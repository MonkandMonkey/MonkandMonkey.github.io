<!DOCTYPE html>
<html lang="zh-CN">

<!-- Head tag -->
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  <!--Description-->
  

  <!--Author-->
  
  <meta name="author" content="MonkandMonkey">
  

  <!--Open Graph Title-->
  
      <meta property="og:title" content="Metrics used in Classification"/>
  
  <!--Open Graph Description-->
  
  <!--Open Graph Site Name-->
  <meta property="og:site_name" content="Amy"/>
  <!--Type page-->
  
      <meta property="og:type" content="article" />
  
  <!--Page Cover-->
  

  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <!-- Title -->
  
  <title>Metrics used in Classification - Amy</title>


  <link rel="shortcut icon" href="/images/amy/bath.png">

  <!-- Custom CSS/Sass -->
  <link rel="stylesheet" href="/css/style.css">

  <!----------------------------
  https://github.com/GallenHu/hexo-theme-Daily

 _____            _   _
|  __ \          (_) | |
| |  | |   __ _   _  | |  _   _
| |  | |  / _` | | | | | | | | |
| |__| | | (_| | | | | | | |_| |
|_____/   \__,_| |_| |_|  \__, |
                          __/ |
                         |___/

    ---------------------------><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</head>


<body>

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><!-- Nav -->
  <header class="site-header">
  <div class="header-inside">
    <div class="logo">
      <a href="/" rel="home">
        
        <img src="/images/amy/owl.jpg" alt="Amy" height="60">
        
      </a>
    </div>
    <!-- Navigation -->
    <nav class="navbar">
      <!-- Collect the nav links, forms, and other content for toggling -->
      <div class="collapse">
        <ul class="navbar-nav">
          
          
            <li>
              <a href="/.">
                
                  Home
                
              </a>
            </li>
          
            <li>
              <a href="/archives">
                
                  Archive
                
              </a>
            </li>
          
            <li>
              <a href="/about">
                
                  About
                
              </a>
            </li>
          
        </ul>
      </div>
      <!-- /.navbar-collapse -->
    </nav>
    <div class="button-wrap">
      <button class="menu-toggle">Primary Menu</button>
    </div>
  </div>
</header>


  <!-- Main Content -->
  <div class="content-area">
  <div class="post">
    <!-- Post Content -->
    <div class="container">
      <article>
        <!-- Title date & tags -->
        <div class="post-header">
          <h1 class="entry-title">
            Metrics used in Classification
            
          </h1>
          <p class="posted-on">
          2018-03-24
          </p>
          <div class="tags-links">
            
              
                <a href="/tags/classification/" rel="tag">
                  classification
                </a>
              
                <a href="/tags/metrics/" rel="tag">
                  metrics
                </a>
              
            
          </div>
        </div>
        <!-- Post Main Content -->
        <div class="entry-content">
          <p>We will introduce common metrics used in classification problems: <em>precision, recall, f1, macro_f1, micro_f1, precision-recall curve and ROC curve </em>. Our discussion is based on <strong>binary classification</strong> problems.</p>
<h2 id="Table-of-Prediction"><a href="#Table-of-Prediction" class="headerlink" title="Table of Prediction"></a>Table of Prediction</h2><p><img src="https://ws1.sinaimg.cn/large/006tNbRwly1fq2uzp9bqgj30f3072gmz.jpg" alt="Table 1. Prediction table"></p>
<p>Based on this table, we will give the definition of precision, recall and f1, f1 is defined as the <em>harmonic mean</em> of precision and recall.</p>
<p>$ precision = \frac{TP}{TP + FP} $</p>
<p>$ recall = \frac{TP}{TP + FN} $</p>
<p>$ f1 = \frac{2}{\frac{1}{precision} \times \frac{1}{precision}} = 2 \times \frac{precision \times recall}{precision + recall}$</p>
<p><strong> precision </strong>: among the samples you predict, how many are correctly predict.</p>
<p><strong> recall </strong>: among all the postive samples, how many are found by your model.</p>
<p><strong> f1 </strong>: a tradeoff for precision and recall for <em>different threshold</em> (we got a probability when predict, if the prob is larger than threshold, we will predict it as postive and vice versa).</p>
<h2 id="Macro-and-Micro"><a href="#Macro-and-Micro" class="headerlink" title="Macro and Micro"></a>Macro and Micro</h2><p>Macro and micro are different average ways.<br>Macro f1 treated each class equally, i.e. it doesn’t take each class’ sample num into consideration. Whereas micro f1 take each class’ sample num into consideration, i.e. it computes the weighted average f1 for each class.<br>Suppose we have $n_0$ samples for class 0, $n_1$ samples for class 1, and $f1_0$ is f1 score for class 0, $f1_1$ is f1 score for class 1. Then</p>
<p>$ macrof1 = \frac{1}{2} \times (f1_0 + f1_1) $</p>
<p>$ microf1 = \frac{n_0 \times f1_0 + n_1 \times f1_1}{n_0 + n_1}$</p>
<h2 id="Confusion-Matrix"><a href="#Confusion-Matrix" class="headerlink" title="Confusion Matrix"></a>Confusion Matrix</h2><p>Confusion matrix is a matrix used to evaluate the accuracy for classification. Each element $C(i, j)$ is the number of samples known to be in group $i$ but predicted to be in group $j$. If $ i == j$ then $C(i, j)$ is the correctly predict num for class $i$. Usually confusion matrix is plotted using a heat map.<br><img src="/images/cls_metrics/cm_plot.png" alt="Confusion Matrix"></p>
<h2 id="Precision-Recall-Curve"><a href="#Precision-Recall-Curve" class="headerlink" title="Precision Recall Curve"></a>Precision Recall Curve</h2><p>Precision Recall Curve shows the relationship between recall(x) and precision(y).<br>It is plotted by adjusting $thereshold$ when predicting labels. Given a trained classifier, we use it to predict some new samples, then we get a list of probabilities, if the probability is larger than $threshold$, we assign it as postive label, else we assign it as negative label. So when we adjust the threshold value, we will get a group of (precision, recall) pairs. Precision Recall Curve is plotted using these pairs.<br><img src="/images/cls_metrics/PR_plot.png" alt="Precision Recall Curve"></p>
<h2 id="ROC-curve-and-AUC-of-ROC"><a href="#ROC-curve-and-AUC-of-ROC" class="headerlink" title="ROC curve and AUC of ROC"></a>ROC curve and AUC of ROC</h2><p>ROC Curve shows the relationship between TPR(x) and FPR(y).</p>
<p>$ TPR = \frac{TP}{TP + FN} $</p>
<p>$ FPR = \frac{FP}{FP + TN} $</p>
<p>Similar to Precision Recall Curve, ROC curve is also plotted by adjusting $thereshold$ when predicting labels.<br>AUC (area under curve) is the area under the ROC curve.<br><img src="/images/cls_metrics/ROC_plot.png" alt="ROC Curve"></p>
<h2 id="Trial"><a href="#Trial" class="headerlink" title="Trial"></a>Trial</h2><p>Finally, we use sklearn to train a binary classifier and evaluate this classifier using the above metrics.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div></pre></td><td class="code"><pre><div class="line"><span class="string">"""</span></div><div class="line">Binary classification.</div><div class="line">Try scikit learn's classifier with auto generated dataset.</div><div class="line">"""</div><div class="line"><span class="keyword">import</span> itertools</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> svm</div><div class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> f1_score, precision_recall_curve, average_precision_score, roc_auc_score, roc_curve, \</div><div class="line">    confusion_matrix</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_classification</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">make_dataset</span><span class="params">()</span>:</span></div><div class="line">    <span class="comment"># generate dataset for binary classification</span></div><div class="line">    X, y = make_classification(n_samples=<span class="number">500</span>, n_classes=<span class="number">2</span>, n_features=<span class="number">4</span>, n_informative=<span class="number">2</span>, flip_y=<span class="number">0.28</span>,</div><div class="line">                               weights=[<span class="number">0.4</span>, <span class="number">0.6</span>], random_state=<span class="number">101</span>)</div><div class="line">    <span class="comment"># plot dataset</span></div><div class="line">    plt.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], marker=<span class="string">"o"</span>, c=y, s=<span class="number">25</span>, edgecolor=<span class="string">"k"</span>)</div><div class="line">    plt.show()</div><div class="line">    <span class="comment"># split dataset</span></div><div class="line">    train_size = <span class="number">400</span></div><div class="line">    train_x, train_y = X[:train_size], y[:train_size]</div><div class="line">    test_x, test_y = X[train_size:], y[train_size:]</div><div class="line">    <span class="keyword">return</span> train_x, train_y, test_x, test_y</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(train_x, train_y)</span>:</span></div><div class="line">    clf = svm.SVC()</div><div class="line">    clf.fit(train_x, train_y)</div><div class="line">    <span class="keyword">return</span> clf</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(clf, test_x)</span>:</span></div><div class="line">    probs = clf.decision_function(test_x)</div><div class="line">    preds = clf.predict(test_x)</div><div class="line">    <span class="keyword">return</span> probs, preds</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">macro_average</span><span class="params">(arr)</span>:</span></div><div class="line">    <span class="keyword">return</span> np.average(arr)</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">micro_average</span><span class="params">(cls_sample_nums, arr)</span>:</span></div><div class="line">    <span class="keyword">return</span> np.dot(cls_sample_nums, arr) / np.sum(cls_sample_nums)</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate</span><span class="params">(probs, pred_y, true_y)</span>:</span></div><div class="line">    <span class="comment"># plot precision_recall curve</span></div><div class="line">    avg_precision = average_precision_score(true_y, probs)</div><div class="line">    precision, recall, _ = precision_recall_curve(true_y, probs)</div><div class="line">    print(<span class="string">"Average precision: &#123;:.04f&#125;"</span>.format(avg_precision))</div><div class="line"></div><div class="line">    plt.step(recall, precision, color=<span class="string">'b'</span>, alpha=<span class="number">0.2</span>, where=<span class="string">'post'</span>)</div><div class="line">    plt.xlabel(<span class="string">'Recall'</span>)</div><div class="line">    plt.ylabel(<span class="string">'Precision'</span>)</div><div class="line">    plt.ylim([<span class="number">0.0</span>, <span class="number">1.05</span>])</div><div class="line">    plt.xlim([<span class="number">0.0</span>, <span class="number">1.0</span>])</div><div class="line">    plt.title(<span class="string">'2-class Precision-Recall curve: AP=&#123;0:0.2f&#125;'</span>.format(avg_precision))</div><div class="line">    plt.show()</div><div class="line"></div><div class="line">    <span class="comment"># plot roc curve and auc</span></div><div class="line">    fpr, tpr, _ = roc_curve(true_y, probs)</div><div class="line">    mAP = roc_auc_score(true_y, probs)</div><div class="line">    print(<span class="string">"Mean average precision: &#123;:.04f&#125;"</span>.format(mAP))</div><div class="line"></div><div class="line">    plt.plot(np.arange(<span class="number">0</span>, <span class="number">1.1</span>, <span class="number">0.1</span>), np.arange(<span class="number">0</span>, <span class="number">1.1</span>, <span class="number">0.1</span>), <span class="string">"k--"</span>)</div><div class="line">    plt.step(fpr, tpr, color=<span class="string">'g'</span>, alpha=<span class="number">0.2</span>, where=<span class="string">'post'</span>)</div><div class="line">    plt.xlabel(<span class="string">'False Positive Rate'</span>)</div><div class="line">    plt.ylabel(<span class="string">'True Positive Rate'</span>)</div><div class="line">    plt.ylim([<span class="number">0.0</span>, <span class="number">1.05</span>])</div><div class="line">    plt.xlim([<span class="number">0.0</span>, <span class="number">1.0</span>])</div><div class="line">    plt.title(<span class="string">'2-class ROC curve: AUC=&#123;0:0.2f&#125;'</span>.format(mAP))</div><div class="line">    plt.show()</div><div class="line"></div><div class="line">    <span class="comment"># plot confusion matrix</span></div><div class="line">    cm = confusion_matrix(true_y, pred_y)</div><div class="line">    <span class="comment"># normalize cm as the sample num for each class varies</span></div><div class="line">    cm = cm.astype(<span class="string">'float'</span>) / cm.sum(axis=<span class="number">1</span>)[:, np.newaxis]</div><div class="line"></div><div class="line">    plt.imshow(cm, interpolation=<span class="string">'nearest'</span>, cmap=plt.cm.Blues)</div><div class="line">    plt.title(<span class="string">"Confusion matrix"</span>)</div><div class="line">    plt.colorbar()</div><div class="line">    class_names = [<span class="string">"0"</span>, <span class="string">"1"</span>]</div><div class="line">    tick_marks = np.arange(len(class_names))</div><div class="line">    plt.xticks(tick_marks, class_names)</div><div class="line">    plt.yticks(tick_marks, class_names)</div><div class="line"></div><div class="line">    fmt = <span class="string">'.2f'</span></div><div class="line">    thresh = cm.max() / <span class="number">2.</span></div><div class="line">    <span class="keyword">for</span> i, j <span class="keyword">in</span> itertools.product(range(cm.shape[<span class="number">0</span>]), range(cm.shape[<span class="number">1</span>])):</div><div class="line">        plt.text(j, i, format(cm[i, j], fmt),</div><div class="line">                 horizontalalignment=<span class="string">"center"</span>,</div><div class="line">                 color=<span class="string">"white"</span> <span class="keyword">if</span> cm[i, j] &gt; thresh <span class="keyword">else</span> <span class="string">"black"</span>)</div><div class="line"></div><div class="line">    plt.tight_layout()</div><div class="line">    plt.ylabel(<span class="string">'True label'</span>)</div><div class="line">    plt.xlabel(<span class="string">'Predicted label'</span>)</div><div class="line">    plt.show()</div><div class="line"></div><div class="line">    <span class="comment"># micro_f1 and macro_f1</span></div><div class="line">    f1_cls0 = f1_score(test_y, pred_y, average=<span class="string">"binary"</span>, pos_label=<span class="number">0</span>)</div><div class="line">    f1_cls1 = f1_score(test_y, pred_y, average=<span class="string">"binary"</span>, pos_label=<span class="number">1</span>)</div><div class="line">    print(<span class="string">"f1 for class 0: &#123;:.4f&#125;"</span>.format(f1_cls0))</div><div class="line">    print(<span class="string">"f1 for class 1: &#123;:.4f&#125;"</span>.format(f1_cls1))</div><div class="line">    cls_sample_nums = np.bincount(test_y)</div><div class="line">    <span class="comment"># micro_f1 = f1_score(test_y, pred_y, average="micro")</span></div><div class="line">    <span class="comment"># macro_f1 = f1_score(test_y, pred_y, average="macro")</span></div><div class="line">    micro_f1 = micro_average(cls_sample_nums, [f1_cls0, f1_cls1])</div><div class="line">    macro_f1 = macro_average([f1_cls0, f1_cls1])</div><div class="line">    print(<span class="string">"Micro f1: &#123;:.4f&#125;"</span>.format(micro_f1))</div><div class="line">    print(<span class="string">"Macro f1: &#123;:.4f&#125;"</span>.format(macro_f1))</div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div><div class="line">    train_x, train_y, test_x, test_y = make_dataset()</div><div class="line">    clf = train(train_x, train_y)</div><div class="line">    pred_probs, pred_y = predict(clf, test_x)</div><div class="line">    evaluate(pred_probs, pred_y, test_y)</div></pre></td></tr></table></figure></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="string">""" console outputs: """</span></div><div class="line">Average precision: <span class="number">0.8917</span></div><div class="line">Mean average precision: <span class="number">0.8506</span></div><div class="line">f1 <span class="keyword">for</span> <span class="class"><span class="keyword">class</span> 0:</span> <span class="number">0.7561</span></div><div class="line">f1 <span class="keyword">for</span> <span class="class"><span class="keyword">class</span> 1:</span> <span class="number">0.8305</span></div><div class="line">Micro f1: <span class="number">0.7993</span></div><div class="line">Macro f1: <span class="number">0.7933</span></div></pre></td></tr></table></figure>
<h2 id="References"><a href="#References" class="headerlink" title="References:"></a>References:</h2><ol>
<li><a href="http://scikit-learn.org/stable/modules/model_evaluation.html#roc-metrics" target="_blank" rel="noopener">Scikit Learn</a></li>
<li><a href="https://www.clips.uantwerpen.be/~vincent/pdf/microaverage.pdf" target="_blank" rel="noopener">Macro- and micro-averaged evaluation measures</a></li>
</ol>

        </div>
      </article>
    </div>
    <!-- Comments -->
    <div class="container">
      



    </div>
    <!-- Pre or Next -->
    <div class="nav-links">
      
        <div class="nav-previous">
          <a href="/2018/04/30/Expected-Value-and-Variance-of-Normal-Distribution/" rel="prev"><span class="meta-arraw meta-arraw-left"></span> Older Posts</a>
        </div>
      
      
        <div class="nav-next">
          <a href="/2018/03/17/Excel-Sheet-Column/" rel="prev">Newer Posts <span class="meta-arraw meta-arraw-right"></span></a>
        </div>
      
    </div>

  </div>
</div>


  <!-- Footer -->
  <!-- Footer-widgets -->
<div class="footer-widgets">
  <div class="row inside-wrapper">
    <div class="col-1-3">
      <aside>
        <h1 class="widget-title">Me</h1>
        <div class="custom-widget-content">
          
          <ul><li>MonkandMonkey</li></ul>
        </div>
      </aside>
    </div>
    <div class="col-1-3">
      <aside>
        <h1 class="widget-title">Contact</h1>
        <div class="widget-text">
          
            
              <a href="https://github.com/MonkandMonkey" class="icon icon-github" target="_blank">github</a>
            
              <a href="mailto:chenjing.amy@pku.edu.cn" class="icon icon-mail" target="_blank">mail</a>
            
          
        </div>
      </aside>
    </div>
    
    <div class="col-1-3">
      <aside>
        <h1 class="widget-title">Search</h1>
        <div class="widget-text">
          <form onSubmit="return appDaily.submitSearch('')">
            <p>
              <input type="text" placeholder="search..." id="homeSearchInput">
            </p>
             <!--<input type="submit" value="GO">-->
          </form>
        </div>
      </aside>
    </div> 
  </div>
</div>
<!-- Footer -->
<footer class="site-info">
  <p>
    <span>Amy &copy; 2019</span>
    
      <span class="split">|</span>
      <span>Powered by MonkandMonkey</a></span>
    
  </p>
</footer>


  <!-- After footer scripts -->
  <!-- scripts -->
<script src="/js/app.js"></script>

<script>
  var disqus_shortname = 'monkandmonkey3';

  
  var disqus_url = 'http://localhost:4000/2018/03/24/Metrics used in Classification/';
  

  (function(){
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/count.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->





</body>

</html>