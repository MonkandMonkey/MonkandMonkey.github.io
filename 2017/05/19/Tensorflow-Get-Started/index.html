<!DOCTYPE html>
<html lang="zh-CN">

<!-- Head tag -->
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  <!--Description-->
  

  <!--Author-->
  
  <meta name="author" content="MonkandMonkey">
  

  <!--Open Graph Title-->
  
      <meta property="og:title" content="Tensorflow Get Started"/>
  
  <!--Open Graph Description-->
  
  <!--Open Graph Site Name-->
  <meta property="og:site_name" content="Amy"/>
  <!--Type page-->
  
      <meta property="og:type" content="article" />
  
  <!--Page Cover-->
  

  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <!-- Title -->
  
  <title>Tensorflow Get Started - Amy</title>


  <link rel="shortcut icon" href="/images/amy/bath.png">

  <!-- Custom CSS/Sass -->
  <link rel="stylesheet" href="/css/style.css">

  <!----------------------------
  https://github.com/GallenHu/hexo-theme-Daily

 _____            _   _
|  __ \          (_) | |
| |  | |   __ _   _  | |  _   _
| |  | |  / _` | | | | | | | | |
| |__| | | (_| | | | | | | |_| |
|_____/   \__,_| |_| |_|  \__, |
                          __/ |
                         |___/

    ---------------------------><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</head>


<body>

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><!-- Nav -->
  <header class="site-header">
  <div class="header-inside">
    <div class="logo">
      <a href="/" rel="home">
        
        <img src="/images/amy/owl.jpg" alt="Amy" height="60">
        
      </a>
    </div>
    <!-- Navigation -->
    <nav class="navbar">
      <!-- Collect the nav links, forms, and other content for toggling -->
      <div class="collapse">
        <ul class="navbar-nav">
          
          
            <li>
              <a href="/.">
                
                  Home
                
              </a>
            </li>
          
            <li>
              <a href="/archives">
                
                  Archive
                
              </a>
            </li>
          
            <li>
              <a href="/about">
                
                  About
                
              </a>
            </li>
          
        </ul>
      </div>
      <!-- /.navbar-collapse -->
    </nav>
    <div class="button-wrap">
      <button class="menu-toggle">Primary Menu</button>
    </div>
  </div>
</header>


  <!-- Main Content -->
  <div class="content-area">
  <div class="post">
    <!-- Post Content -->
    <div class="container">
      <article>
        <!-- Title date & tags -->
        <div class="post-header">
          <h1 class="entry-title">
            Tensorflow Get Started
            
          </h1>
          <p class="posted-on">
          2017-05-19
          </p>
          <div class="tags-links">
            
              
                <a href="/tags/tech/" rel="tag">
                  tech
                </a>
              
                <a href="/tags/python/" rel="tag">
                  python
                </a>
              
                <a href="/tags/tensorflow/" rel="tag">
                  tensorflow
                </a>
              
                <a href="/tags/machine learning/" rel="tag">
                  machine learning
                </a>
              
            
          </div>
        </div>
        <!-- Post Main Content -->
        <div class="entry-content">
          <p>这篇博客的主要内容来自于<strong>Tensorflow的英文官方教程</strong>：
<a href="https://www.tensorflow.org/get_started/get_started" target="_blank" rel="external">Getting started with tensorflow!</a>，同时加入了个人的理解和知识点的扩充。<br>
<strong>感谢上面那篇文章的作者，很棒的入门的教程！</strong></p>
<p>Tensorflow——An open-source software library for Machine Intelligence
--致力于深度学习的Python开源库。</p>
<ul>
<li>Lowlevel API：较为底层的API，适合高级使用者:比较care模型性能的研究人员，和对底层代码很感兴趣的人员。</li>
<li>Highlevel API: 高层一点的API，较lowlevel API好学，易用。能够帮助你方便地管理datasets，模型，完成训练和预测的工作。</li>
<li>请注意那些名字里有_contrib_的API: 这些API仍在developing阶段，tensorflow的代码是开源的，这意味着那些API可能处于变化中。如果感兴趣，你也可以加入到tensorflow的coding队伍中，变成一个为其他开发人员设计工具的开发人员。</li>
</ul>
<p>我的寄语：<br>
Dear friend,<br>
建议你在学习tensorflow之前，</p>
<ul>
<li>丰富自己的__想象力__， 因为你的脑海中需要构建出一幅__data flow graph__，这幅图能让你的代码思路更加清晰，这很重要，尤其是当你的模型越来越复杂，需要使用的tensorflow功能越来越多时。</li>
<li>不要着急去看Github上别人写的代码，先花些时间弄懂tensorflow 设计的抽象概念，这在之后能够帮助你快速理解别人的代码，并且自己也能够写出更棒的代码！</li>
<li>Tensorflow官网的documents很多，如果你是一个完完全全的新手，建议你从<a href="https://www.tensorflow.org/get_started/get_started" target="_blank" rel="external">Getting Started With TensorFlow</a>开始学习。</li>
<li>学习资料比较长，请多一点耐心读完，并且随时动手敲代码！</li>
</ul>
<h2>1. 必须理解的概念：</h2>
<ol>
<li>
<p>Tensors: (数据)<br>
任意维数的array，tensor的rank指的是array的维度:<br>
eg.<br>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># tensor examples</span></div><div class="line"><span class="number">3</span> <span class="comment"># rank:0, 1-d array, shape:[]</span></div><div class="line">[<span class="number">1.</span>,<span class="number">2.</span>,<span class="number">3.</span>] <span class="comment"># rank:1, 1-d array, shape:[3]</span></div><div class="line">[[<span class="number">1.</span>,<span class="number">2.</span>,<span class="number">3.</span>], [<span class="number">2.</span>,<span class="number">1.</span>,<span class="number">3.</span>]] <span class="comment"># rank:2, 2-d array or matrix, shape:[2, 3]</span></div><div class="line">[[[<span class="number">1.</span>,<span class="number">2.</span>,<span class="number">3.</span>], [<span class="number">2.</span>,<span class="number">1.</span>,<span class="number">3.</span>]]] <span class="comment"># rank:3, 3-d array or matrix, shape:[1, 2, 3]</span></div></pre></td></tr></table></figure></p>
<p>tensorflow把封装成一个Python类，使用类中的方法，可以方便地对array进行管理和操作。</p>
</li>
<li>
<p>Computational Graph: (计算图)
数据量越大，计算过程越复杂，越需要一个清晰的思路整理数据处理的流程。Tensorflow通过data flow graph来记录对每部分数据要分别进行什么操作。<br>
<img src="/images/tensorflow/Computational-graph.jpg" alt="Computational graph"><br>
Tensorflow把对数据的操作化作directed graph中的节点，数据（tensor）就是节点直接相连的边，可以想象数据在图上有向地流动，每次流进节点就会进行某种指定的操作，然后流出的是操作之后的数据。Tensorflow这个名字很明确地表达了自己的本质呢。
简单说来，tensorflow做的事情主要分为两步：</p>
<ol>
<li>生成computational graph;</li>
<li>执行computational graph;</li>
</ol>
<p>Computational graph的node，接受0个或任意多个tensor作为input，然后output一个tensor作为输出。是的，node可以没有输入，例如node本身就是一个constant，它不接受任何输入，执行的动作是：把存储在自己内部的数值输出。下面我们创建两个constant node试试看：</p>
<p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">const_node_1 = tf.constant(<span class="number">3.0</span>, tf.float32)</div><div class="line">const_node_2 = tf.constant(<span class="number">4.0</span>) <span class="comment"># float默认就是tf.float32，可以不必显式指明</span></div><div class="line">const_node_3 = tf.constant(<span class="number">5</span>)   <span class="comment"># int 类型</span></div><div class="line"><span class="comment"># output</span></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>const_node_1</div><div class="line">&lt;tf.Tensor <span class="string">'Const_11:0'</span> shape=() dtype=float32&gt;</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>const_node_2</div><div class="line">&lt;tf.Tensor <span class="string">'Const_10:0'</span> shape=() dtype=float32&gt;</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>const_node_3</div><div class="line">&lt;tf.Tensor <span class="string">'Const_9:0'</span> shape=() dtype=int32&gt;</div></pre></td></tr></table></figure></p>
<p>这里并没有显示每个constant内部存储的值，但是别担心，在它们真正参与计算时，3.0,4.0和5都会乖乖出现的。这里我们只是生成了一个包含三个constant nodes的computational graph，它现在是静态的，并没有进行任何实质上的操作，下一步我们通过run这个graph，让数据真正地flow起来!</p>
</li>
<li>
<p>Session：(会话)<br>
Computational graph的运行必需要处在一个叫做：session的环境中才可以进行，session像一个厉害的大管家，为我们隔离了许多复杂的控制和状态，让我们不必为这些琐碎的问题操心。下面我们就来创建一个session，期待看到数据流动起来的样子：<br>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">sess = tf.Session()</div><div class="line">print(sess.run(const_node_1, const_node_2))</div><div class="line"><span class="comment"># output</span></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>sess</div><div class="line">&lt;tensorflow.python.client.session.Session object at <span class="number">0x7f5fddfaab38</span>&gt;</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>print(sess.run([const_node_1, const_node_2]))</div><div class="line">[<span class="number">3.0</span>, <span class="number">4.0</span>] <span class="comment"># 3.0 and 4.0 as we expected</span></div></pre></td></tr></table></figure></p>
<p>来点更复杂一些的操作：比如让上面两个节点的值相加：3.0 + 4.0
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">add_node_1 = tf.add(const_node_1, const_node_2)</div><div class="line">print(sess.run(add_node_1))</div><div class="line"><span class="comment"># output</span></div><div class="line"><span class="number">7.0</span></div></pre></td></tr></table></figure></p>
</li>
<li>
<p>Placeholder: (data)
可能你还是觉得太简单了，两个常数相加挺无聊的，我想自己指定两个加数的值：<br>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">a = tf.placeholder(tf.float32)</div><div class="line">b = tf.placeholder(tf.float32)</div><div class="line">add_node_2 = tf.add(a, b) <span class="comment"># + 是 tf.add()的简洁形式</span></div><div class="line"><span class="comment"># output</span></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>print(sess.run(add_node_2, &#123;a:<span class="number">1</span>, b:<span class="number">5</span>&#125;)) <span class="comment"># 虽然是int, 仍然当成tf.float32</span></div><div class="line"><span class="number">6.0</span></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>print(sess.run(add_node_2, &#123;a:[<span class="number">1</span>,<span class="number">3</span>], b:[<span class="number">2.2</span>,<span class="number">3.4</span>]&#125;))</div><div class="line">[ <span class="number">3.20000005</span>  <span class="number">6.4000001</span> ]</div></pre></td></tr></table></figure></p>
<p>这里我们用到了_Placeholder_：它相当于函数在定义时的形参，在使用的时候就会被赋予具体的值;同时我们可以指定传入参数的类型：eg.tf.float32。Placeholder在定义时不能初始化，它的赋值必须在run时进行。<br>
注：观察到上面1 + 2.2 和3+3.4的结果比真实值稍稍大了一点点，通过尝试tf.float16, tf.float64的	placeholder(), 可以发现，小数的精度越高这个误差越小。<br>
下面我们更进一步实现(a + b) * c 的计算过程：</p>
<p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 使用两个node实现</span></div><div class="line">c = tf.placeholder(tf.float32)</div><div class="line">add_mult_node_1 = add_node_2 * c</div><div class="line"><span class="comment"># output</span></div><div class="line">print(sess.run(add_mult_node_1, &#123;a:<span class="number">1.1</span>, b:<span class="number">2.2</span>, c:<span class="number">3.</span>&#125;))</div><div class="line"><span class="number">9.9</span></div><div class="line"><span class="comment"># 使用一个node实现</span></div><div class="line">add_mult_node_2 = (a + b) * c</div><div class="line"><span class="comment"># output</span></div><div class="line">print(sess.run(add_mult_node_2, &#123;a:<span class="number">1.1</span>, b:<span class="number">2.2</span>, c:<span class="number">3.</span>&#125;))</div><div class="line"><span class="number">9.9</span></div></pre></td></tr></table></figure></p>
<p>在这个过程中，我们需要在心里绘制出一幅computational graph， 如果操作很多也可以直接画在纸上。<br>
<strong>Important</strong>: Placeholder如果在定义时被赋值，将会报错! Its value must be fed using the feed_dict 	optional argument to Session.run(), Tensor.eval(), or Operation.run().</p>
</li>
<li>
<p>Variables：(params)<br>
在Tensorflow中，我们使用Variables来存储和更新parameters。 Variables 是存储在内存中的 tensors. 它们必须在launch graph之前显式初始化，还可以training过程中和training结束之后存储到你的磁盘上，以便下次直接使用该模型。T</p>
<p>我们需要明确Placeholder和Variable的使用：</p>
<ul>
<li>Input data 通常声明为Placeholder</li>
<li>Model的参数通常声明为Variable</li>
<li>Placeholder 为feed data而生，定义时不能赋值，其内容为空，执行时通过run(),eval()等方法赋予实际值</li>
<li>Variable 为模型参数而生，定义时必须提供初值，数据类型可以是任意type、shape的Tensor 。</li>
</ul>
<p>下面我们通过一个简单的Linear Model看看如何使用Variable定义模型参数：lm = W * x + b
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">W = tf.Variable([<span class="number">.3</span>], tf.float32)</div><div class="line">b = tf.Variable([<span class="number">-.3</span>], tf.float32)</div><div class="line">x = tf.placeholder(tf.float32)</div><div class="line">linear_model = W * x + b</div></pre></td></tr></table></figure></p>
<p>初始化Variables:<br>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">init = tf.global_variables_initializer()</div><div class="line">sess.run(init)</div></pre></td></tr></table></figure></p>
<p>run init会初始化整个graph中的所有全局Variables；TensorFlow是lazy执行的，在run之前，所有的Variables都没有被赋予实际的值。<br>
下一步我们feed一组input样本x给我们可爱的linear model，看它会有什么输出：<br>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">print(sess.run(linear_model, &#123;x:[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>]&#125;))</div><div class="line"><span class="comment"># output</span></div><div class="line">[ <span class="number">0.</span>          <span class="number">0.30000001</span>  <span class="number">0.60000002</span>  <span class="number">0.90000004</span>]</div></pre></td></tr></table></figure></p>
<p>现在我们需要知道这个linear_model的预测效果如何，接下来我们将给出样本的真实值_y_, 通过_loss_function_对比模型的输出_y_m_和真实值y之间的差异。loss function的类型很多，这里选择简单的平方误差函数：loss = (y_m - y)^2</p>
<p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">y = tf.placeholder(tf.float32)</div><div class="line">squared_deltas = tf.square(linear_model - y) <span class="comment"># 单个样本预测误差</span></div><div class="line">loss = tf.reduce_sum(squared_deltas) 		 <span class="comment"># 整体样本预测误差</span></div><div class="line">print(sess.run(loss, &#123;x: [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>], y: [<span class="number">0</span>,<span class="number">-1</span>,<span class="number">-2</span>,<span class="number">-3</span>]&#125;))</div><div class="line"><span class="comment"># output</span></div><div class="line"><span class="number">23.66</span></div></pre></td></tr></table></figure></p>
<p><img src="/images/tensorflow/origin_lm.png" alt="Origin Linear Model"><br>
哎呀，这个模型的误差足足有_23.66_，效果不够理想！我们需要对它进行改进，通常训练模型的过程会通过最小化误差函数自动调整模型参数，从而使模型达到最优，这里我们为了方便，就直接给出最优模型。best_linear_model = -1.0 * x + 1.0， 这一步我们更新模型参数W,b的值为-1.0， 1.0。
更新Variable的值，可以通过tf.assign()方法实现：
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># assign best val for W and b</span></div><div class="line">fix_W = tf.assign(W, [<span class="number">-1.</span>])</div><div class="line">fix_b = tf.assign(b, [<span class="number">1.</span>])</div><div class="line"><span class="comment"># do the operation acturally</span></div><div class="line">sess.run([fix_W, fix_b])</div><div class="line">print(sess.run(loss, &#123;x: [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>], y: [<span class="number">0</span>,<span class="number">-1</span>,<span class="number">-2</span>,<span class="number">-3</span>]&#125;))</div><div class="line"><span class="comment"># output</span></div><div class="line"><span class="number">0.0</span></div></pre></td></tr></table></figure></p>
<p>现在model的loss是0，效果有了很大的提升！</p>
</li>
<li>
<p>自动调参：<br>
既然是_machine learning_，不能每次都手动更新参数吧，别着急，这一步我们学习如何自动更新模型参数，从而提升预测效果。<br>
Tensorflow提供了许多类型的optimizer，在train阶段，这些optimizer能够自动优化你指定的__目标函数__，通常是让损失函数达到最小。tf.train.GradientDescentOptimizer是最简单的optimizer。<br>
其原理是：梯度下降法。把要优化的目标函数想象成一座座连绵的山，我们从山中的任意一点开始下山，目标是尽快到达山下的_最低点_，梯度下降法的策略是：求当前位置的梯度g（最陡的方向下山最快），然后沿着梯度的负方向走一步，这一步应该迈的距离是learning_rate，也叫_步长_。步长的太大可能会导致错过最低点，太小又可能导致收敛的太慢，因此需要小心地选择一个合适的步长。
备注: GradientDescent算法不能保证每次都收敛到全局最优解，有时候你很可能得到的只是一个局部最优解。
当然，optimizer使用起来十分easy，因为它就是个黑盒子，我们只需要告诉它要优化的目标函数，它就会自动帮我们找到最优解。
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># choose an optimizer</span></div><div class="line">optimizer = tf.train.GradientDescentOptimizer(<span class="number">0.01</span>)</div><div class="line"><span class="comment"># tell it what to do next</span></div><div class="line">train = optimizer.minimize(loss)</div><div class="line"><span class="comment"># init W, b with</span></div><div class="line">sess.run(init)  </div><div class="line"><span class="comment"># train loop</span></div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1000</span>):</div><div class="line">  sess.run(train, &#123;x:[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>], y:[<span class="number">0</span>,<span class="number">-1</span>,<span class="number">-2</span>,<span class="number">-3</span>]&#125;)</div><div class="line">print(sess.run([W, b]))</div><div class="line"><span class="comment"># output</span></div><div class="line">[array([<span class="number">-0.9999969</span>], dtype=float32), array([ <span class="number">0.99999082</span>],</div><div class="line"> dtype=float32)]</div></pre></td></tr></table></figure></p>
<p>经过1000次迭代之后，W,b 已经十分接近标准答案-1.0,1.0了，我们完成了就是自动学习参数的过程！</p>
</li>
</ol>
<h2>2. 完整的模型训练过程：</h2>
<p>上一步我们直接给出了模型的最优参数，接下来我们进行一次真正意义上的_Machine Learning_，让模型自己学习出最优的W,b。
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#!/usr/bin/python</span></div><div class="line"><span class="comment"># -*-coding:utf-8-*-</span></div><div class="line"></div><div class="line"><span class="string">"""complete_example_tf.py</span></div><div class="line">Description: a complete example for tensorflow tutorial.</div><div class="line">Date: 2017-05-19</div><div class="line">Author: MonkandMonkey</div><div class="line">"""</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># ============================</span></div><div class="line"><span class="comment"># A complete tensorflow example</span></div><div class="line"><span class="comment"># ============================</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">complete_try</span><span class="params">()</span>:</span></div><div class="line">    <span class="comment"># max iteration times</span></div><div class="line">    max_iter = <span class="number">1000</span></div><div class="line">    <span class="string">'''Construct the computational graph'''</span></div><div class="line">    <span class="comment"># model parameters</span></div><div class="line">    W = tf.Variable([<span class="number">.3</span>], tf.float32)</div><div class="line">    b = tf.Variable([<span class="number">-.3</span>], tf.float32)</div><div class="line">    <span class="comment"># model input and output</span></div><div class="line">    x = tf.placeholder(tf.float32)</div><div class="line">    liner_model = W * x + b  <span class="comment"># predict y</span></div><div class="line">    y = tf.placeholder(tf.float32)  <span class="comment"># true y</span></div><div class="line">    <span class="comment"># define loss function</span></div><div class="line">    suqared_deltas = tf.square(liner_model - y)</div><div class="line">    loss = tf.reduce_sum(suqared_deltas)</div><div class="line">    <span class="comment"># choose an optimizer</span></div><div class="line">    optimizer = tf.train.GradientDescentOptimizer(learning_rate=<span class="number">0.01</span>)</div><div class="line">    <span class="comment"># set the train object</span></div><div class="line">    train = optimizer.minimize(loss)</div><div class="line"></div><div class="line">    <span class="string">'''Prepare training data'''</span></div><div class="line">    x_train = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]</div><div class="line">    y_train = [<span class="number">0</span>, <span class="number">-1</span>, <span class="number">-2</span>, - <span class="number">3</span>]</div><div class="line"></div><div class="line">    <span class="string">'''Run the graph'''</span></div><div class="line">    sess = tf.Session()</div><div class="line">    init = tf.global_variables_initializer()</div><div class="line">    sess.run(init)  <span class="comment"># initialize params: W, b</span></div><div class="line">    <span class="comment"># training loop</span></div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(max_iter):</div><div class="line">        <span class="keyword">if</span> i % <span class="number">50</span> == <span class="number">0</span>:</div><div class="line">            curr_W, curr_b, curr_loss = sess.run([W, b, loss], feed_dict=&#123;x: x_train, y: y_train&#125;)</div><div class="line">            print(<span class="string">"[&#123;:0&gt;3&#125;] - W: &#123;:&lt;5.4f&#125;, b: &#123;:&lt;6.4f&#125;, loss: &#123;:&lt;6.4f&#125;"</span>.format(i, curr_W[<span class="number">0</span>], curr_b[<span class="number">0</span>], curr_loss))</div><div class="line">        sess.run(train, feed_dict=&#123;x: x_train, y: y_train&#125;)</div><div class="line"></div><div class="line">    <span class="comment"># evaluate the accuracy</span></div><div class="line">    trained_W, trained_b, trained_loss = sess.run([W, b, loss], feed_dict=&#123;x: x_train, y: y_train&#125;)</div><div class="line">    print(<span class="string">"Training result:"</span>)</div><div class="line">    print(<span class="string">"  W: &#123;:&lt;5.4f&#125;, b: &#123;:&lt;6.4f&#125;, loss: &#123;:&lt;6.4f&#125;"</span>.format(trained_W[<span class="number">0</span>], trained_b[<span class="number">0</span>], trained_loss))</div><div class="line"></div><div class="line">    <span class="keyword">return</span> trained_W[<span class="number">0</span>], trained_b[<span class="number">0</span>]</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># ============================</span></div><div class="line"><span class="comment"># Pic for tensorflow tutorial</span></div><div class="line"><span class="comment"># ============================</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">pic_tensorflow</span><span class="params">(W, b)</span>:</span></div><div class="line">    y = np.array([<span class="number">0</span>, <span class="number">-1</span>, <span class="number">-2</span>, <span class="number">-3</span>])</div><div class="line">    x = np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>])</div><div class="line">    y_m = W * x + b</div><div class="line"></div><div class="line">    plt.plot(x, y, <span class="string">'b.'</span>, x, y_m, <span class="string">'r-'</span>)</div><div class="line"></div><div class="line">    <span class="comment"># add labels</span></div><div class="line">    plt.xlabel(<span class="string">"x"</span>)</div><div class="line">    plt.ylabel(<span class="string">"y"</span>)</div><div class="line">    <span class="comment"># add legends</span></div><div class="line">    plt.legend([<span class="string">"y-truth"</span>, <span class="string">"y-predict"</span>])</div><div class="line">    <span class="comment"># add title</span></div><div class="line">    plt.title(<span class="string">"Best linear_model: W=&#123;:.2f&#125;, b=&#123;:.2f&#125;"</span>.format(W, b))</div><div class="line">    plt.show()</div><div class="line">    print(<span class="string">"Plot pic_tensorflow: a simple plot for tensorflow get started!"</span>)</div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div><div class="line">    print(<span class="string">"Start running!"</span>)</div><div class="line">    W, b = complete_try()<span class="comment"># train the model</span></div><div class="line">    pic_tensorflow(W, b) <span class="comment"># plot the model</span></div></pre></td></tr></table></figure></p>
<p>这里借用tensroflow的computational graph:<br>
<img src="https://www.tensorflow.org/images/getting_started_final.png" alt="Graph for this linear model"><br>
这幅图远比我们想象得要复杂一些，不过很多细节都是tensorflow帮我们补充上的，我们只需要确保那些关键细节正确。</p>
<h2>3. 还能更简单？</h2>
<p><em>tf.contrib.learn</em> 让 Machine learning 的过程进一步地简化，属于更加high level的API，让整个machine learning的过程看起来越来越像你草稿纸上的几行简单的“算法思路”。<br>
仍以Linear Model为例，我们看看使用_tf.contrib.learn_如何完成相同的事情：<br>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</div><div class="line"><span class="comment"># NumPy 包通常用于处理数据</span></div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"></div><div class="line"><span class="comment"># input data：only 1 feature - x</span></div><div class="line">features = [tf.contrib.layers.real_valued_column(<span class="string">"x"</span>, dimension=<span class="number">1</span>)]</div><div class="line"></div><div class="line"><span class="comment"># estimator: provide the handler for model's fitting and evaluation </span></div><div class="line"><span class="comment"># 更多类型的estimator可以查阅API</span></div><div class="line">estimator = tf.contrib.learn.LinearRegressor(feature_columns=features)</div><div class="line"></div><div class="line"><span class="comment"># read and set up data sets.</span></div><div class="line"><span class="comment"># numpy_input_fn: 读入、划分数据集为一个个batch</span></div><div class="line"><span class="comment"># 1 epoch: 使用一遍data set </span></div><div class="line">x = np.array([<span class="number">1.</span>, <span class="number">2.</span>, <span class="number">3.</span>, <span class="number">4.</span>])</div><div class="line">y = np.array([<span class="number">0.</span>, <span class="number">-1.</span>, <span class="number">-2.</span>, <span class="number">-3.</span>])</div><div class="line">input_fn = tf.contrib.learn.io.numpy_input_fn(&#123;<span class="string">"x"</span>: x&#125;, y, batch_size=<span class="number">4</span>,</div><div class="line">                                                  num_epochs=<span class="number">1000</span>)</div><div class="line"><span class="comment"># 训练迭代1000次</span></div><div class="line">estimator.fit(input_fn=input_fn, steps=<span class="number">1000</span>)</div><div class="line"></div><div class="line"><span class="comment"># 检验模型的效果（实际使用应当在test set进行）</span></div><div class="line">print(estimator.evaluate(input_fn=input_fn))</div></pre></td></tr></table></figure></p>
<p>tf.contrib提供了许多常用的model,例如：linear regression,logistic regression, linear classification, logistic classification, and many neural network classifiers and regressors。当然，如果你想自己定制model,也是可以的，下面就是一个自己定制的Linear Model例子：
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># featiures: [x], labels: true y, mode:</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">model</span><span class="params">(features, labels, mode)</span>:</span></div><div class="line">    <span class="comment"># Build a linear model and predict values</span></div><div class="line">    W = tf.get_variable(<span class="string">"W"</span>, [<span class="number">1</span>], dtype=tf.float64)</div><div class="line">    b = tf.get_variable(<span class="string">"b"</span>, [<span class="number">1</span>], dtype=tf.float64)</div><div class="line">    y = W * features[<span class="string">'x'</span>] + b</div><div class="line">    <span class="comment"># Loss sub-graph</span></div><div class="line">    loss = tf.reduce_sum(tf.square(y - labels))</div><div class="line">    <span class="comment"># Training sub-graph</span></div><div class="line">    global_step = tf.train.get_global_step()</div><div class="line">    optimizer = tf.train.GradientDescentOptimizer(<span class="number">0.01</span>)</div><div class="line">    train = tf.group(optimizer.minimize(loss),</div><div class="line">                     tf.assign_add(global_step, <span class="number">1</span>))</div><div class="line">    <span class="comment"># ModelFnOps connects subgraphs we built to the</span></div><div class="line">    <span class="comment"># appropriate functionality.</span></div><div class="line">    <span class="keyword">return</span> tf.contrib.learn.ModelFnOps(</div><div class="line">        mode=mode, predictions=y,</div><div class="line">        loss=loss,</div><div class="line">        train_op=train)</div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div><div class="line">    estimator = tf.contrib.learn.Estimator(model_fn=model)</div><div class="line">    <span class="comment"># define our data set</span></div><div class="line">    x = np.array([<span class="number">1.</span>, <span class="number">2.</span>, <span class="number">3.</span>, <span class="number">4.</span>])</div><div class="line">    y = np.array([<span class="number">0.</span>, <span class="number">-1.</span>, <span class="number">-2.</span>, <span class="number">-3.</span>])</div><div class="line">    input_fn = tf.contrib.learn.io.numpy_input_fn(&#123;<span class="string">"x"</span>: x&#125;, y, <span class="number">4</span>, num_epochs=<span class="number">1000</span>)</div><div class="line">    <span class="comment"># train</span></div><div class="line">    estimator.fit(input_fn=input_fn, steps=<span class="number">1000</span>)</div><div class="line">    <span class="comment"># evaluate our model</span></div><div class="line">    print(estimator.evaluate(input_fn=input_fn, steps=<span class="number">10</span>))</div></pre></td></tr></table></figure></p>
<p>上一部分中的tf.contrib.learn.LinearRegressor，是tf.contrib.learn.Estimator的一个sub-class, 如果我们要定义自己的model, 也需要继承Estimator类。可以通过定义<em>model_fn</em>函数，来描述是一个怎样的model。<em>model_fn</em>中需要指明:fit, loss, evaluate，整个流程看起来非常像我们第二部分中使用low level API实现的例子： 定义parameters, 定义model， 定义loss, optimizer。就好像我们分别设计个几个sub-graphs，然后使用<em>ModelFnOps</em>把各个子图连接起来。</p>
<hr>
<p>读到这里，你应该已经了解了tensorflow的基本套路，面对长长的示例代码也不怕了, 写起代码来也更得心应手。<br>
希望本文对你的理解有所帮助！(<em><sup>_</sup></em>)</p>

        </div>
      </article>
    </div>
    <!-- Comments -->
    <div class="container">
      
<section id="comment">
  <!-- <h1 class="title">Comments</h1> -->

  
  <div id="disqus_thread">
    <script type="text/javascript">
    var disqus_config = function () {
          this.page.url = window.location.href;
          this.page.identifier = 'post-Tensorflow-Get-Started';
          this.page.title = 'Tensorflow Get Started';
      };
    </script>
    <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  </div>
  
</section>




    </div>
    <!-- Pre or Next -->
    <div class="nav-links">
      
        <div class="nav-previous">
          <a href="/2017/05/17/Python中-的疑惑/" rel="prev"><span class="meta-arraw meta-arraw-left"></span> Older Posts</a>
        </div>
      
      
        <div class="nav-next">
          <a href="/2017/05/31/1-字符串转整数/" rel="prev">Newer Posts <span class="meta-arraw meta-arraw-right"></span></a>
        </div>
      
    </div>

  </div>
</div>


  <!-- Footer -->
  <!-- Footer-widgets -->
<div class="footer-widgets">
  <div class="row inside-wrapper">
    <div class="col-1-3">
      <aside>
        <h1 class="widget-title">Me</h1>
        <div class="custom-widget-content">
          
          <ul><li>MonkandMonkey</li></ul>
        </div>
      </aside>
    </div>
    <div class="col-1-3">
      <aside>
        <h1 class="widget-title">Contact</h1>
        <div class="widget-text">
          
            
              <a href="https://github.com/MonkandMonkey" class="icon icon-github" target="_blank">github</a>
            
              <a href="mailto:chenjing.amy@pku.edu.cn" class="icon icon-mail" target="_blank">mail</a>
            
          
        </div>
      </aside>
    </div>
    
    <div class="col-1-3">
      <aside>
        <h1 class="widget-title">Search</h1>
        <div class="widget-text">
          <form onSubmit="return appDaily.submitSearch('')">
            <p>
              <input type="text" placeholder="search..." id="homeSearchInput">
            </p>
             <!--<input type="submit" value="GO">-->
          </form>
        </div>
      </aside>
    </div> 
  </div>
</div>
<!-- Footer -->
<footer class="site-info">
  <p>
    <span>Amy &copy; 2017</span>
    
      <span class="split">|</span>
      <span>Powered by MonkandMonkey</a></span>
    
  </p>
</footer>


  <!-- After footer scripts -->
  <!-- scripts -->
<script src="/js/app.js"></script>

<script>
  var disqus_shortname = 'monkandmonkey3';

  
  var disqus_url = 'http://localhost:4000/2017/05/19/Tensorflow-Get-Started/';
  

  (function(){
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->





</body>

</html>